{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%store -r IMAGE_WIDTH\n",
    "%store -r IMAGE_HEIGHT\n",
    "%store -r MAX_CAPTCHA\n",
    "%store -r CHAR_SET_LEN\n",
    "%store -r charSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImageWH(image):\n",
    "    import numpy as np\n",
    "    \n",
    "    if isinstance(image, str):    \n",
    "        from PIL import Image\n",
    "        image = Image.open(image)\n",
    "        \n",
    "    img_np = np.array(image)\n",
    "    \n",
    "    return img_np.shape[1], img_np.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 25)\n"
     ]
    }
   ],
   "source": [
    "print(GetImageWH('1.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define possible alphabets, numbers\n",
    "# numbers = ['0','1','2','3','4','5','6','7','8','9']\n",
    "# alphabets = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "# ALPHABETs = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "\n",
    "# # Define max captcha = 4 digits\n",
    "# MAX_CAPTCHA = 4 \n",
    "\n",
    "# # Define Image Properties\n",
    "# IMAGE_HEIGHT = 60\n",
    "# IMAGE_WIDTH = 160\n",
    "\n",
    "# # Define char set length\n",
    "# charset = numbers + alphabets + ALPHABETs\n",
    "# CHAR_SET_LEN = len(charset)\n",
    "# print(CHAR_SET_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomCharSet(charCount = 4):\n",
    "    import random as rand\n",
    "#     import ipynb.fs.full.Definitions\n",
    "    \n",
    "    %store -r charSet\n",
    "    \n",
    "    charChoices = []\n",
    "    \n",
    "    for i in range(charCount):\n",
    "        charChoices.append(str(rand.choice(charSet)))\n",
    "    \n",
    "    return charChoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6', '3', 'X', 'T']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(RandomCharSet(4))\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCaptchaTextAndImage(charCount = 4):\n",
    "    from captcha.image import ImageCaptcha\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    \n",
    "    captcha = ImageCaptcha()\n",
    "    charSet = RandomCharSet(charCount)\n",
    "    image = captcha.generate(charSet)\n",
    "    image = Image.open(image)\n",
    "    image = np.array(image)\n",
    "    \n",
    "    return charSet, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', '7', 'W', 'S']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# import ipynb.fs.full.Create_Image\n",
    "# from ipynb.fs.full.Create_Image import GetCaptchaTextAndImage\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "text, image = GetCaptchaTextAndImage()\n",
    "\n",
    "print(text)\n",
    "\n",
    "print(type(image))\n",
    "\n",
    "# imshow(image)\n",
    "# print(image.shape)\n",
    "# print(GetImageWH(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 灰階化\n",
    "def Convert2gray(image):\n",
    "\tif len(image.shape) > 2:\n",
    "\t\tgray = np.mean(image, -1)\n",
    "\t\treturn gray\n",
    "\telse:\n",
    "\t\treturn image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Text To Vector\n",
    "def Text2Vector(text):\n",
    "#     import ipynb.fs.full.Definitions\n",
    "    \n",
    "    text_len = len(text)\n",
    "    if text_len > MAX_CAPTCHA:\n",
    "        raise ValueError('MAX_CAPTCHA out of length')\n",
    "\n",
    "    vector = np.zeros(MAX_CAPTCHA*CHAR_SET_LEN)\n",
    "    \n",
    "    def GetCharIndex(char):\n",
    "        return charSet.index(char)\n",
    "    \n",
    "    for index, char in enumerate(text):\n",
    "        idx = index * CHAR_SET_LEN + GetCharIndex(char)\n",
    "        vector[idx] = 1\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = Text2Vector('hC2a')\n",
    "# print(vec.nonzero()[0])\n",
    "\n",
    "def Vector2Text(vector):\n",
    "    text = []\n",
    "    charPositions = vec.nonzero()[0]\n",
    "    \n",
    "    for index, charPos in enumerate(charPositions):\n",
    "        charIndex = charPos - index * CHAR_SET_LEN\n",
    "        text.append(charSet[charIndex])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateNextBatch(batchSize=128):\n",
    "    import numpy as np\n",
    "    \n",
    "    batch_x = np.zeros([batchSize, IMAGE_HEIGHT*IMAGE_WIDTH])\n",
    "    batch_y = np.zeros([batchSize, MAX_CAPTCHA*CHAR_SET_LEN])\n",
    "\n",
    "    # Make sure image is 160(W) * 60(H) * 3(RGB) format\n",
    "    def GetWrappedCaptchaTextAndImage():\n",
    "#         from ipynb.fs.full.Create_Image import GetCaptchaTextAndImage\n",
    "        \n",
    "        while True:\n",
    "            text, image = GetCaptchaTextAndImage()\n",
    "            if image.shape == (60, 160, 3):#此部分应该与开头部分图片宽高吻合\n",
    "                return text, image\n",
    "\n",
    "    for i in range(batchSize):\n",
    "        text, image = GetWrappedCaptchaTextAndImage()\n",
    "        image = Convert2gray(image)\n",
    "\n",
    "        # 将图片数组一维化 同时将文本也对应在两个二维组的同一行\n",
    "        batch_x[i,:] = image.flatten() / 255 # (image.flatten()-128)/128  mean为0\n",
    "        batch_y[i,:] = Text2Vector(text)\n",
    "\n",
    "    # 返回该训练批次\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.96470588, 0.96470588, 0.96470588, ..., 0.96470588, 0.96470588,\n",
      "        0.96470588],\n",
      "       [0.97385621, 0.97385621, 0.97385621, ..., 0.97385621, 0.97385621,\n",
      "        0.97385621],\n",
      "       [0.9620915 , 0.9620915 , 0.9620915 , ..., 0.9620915 , 0.9620915 ,\n",
      "        0.9620915 ],\n",
      "       ...,\n",
      "       [0.97777778, 0.97777778, 0.97777778, ..., 0.97777778, 0.97777778,\n",
      "        0.97777778],\n",
      "       [0.97385621, 0.97385621, 0.97385621, ..., 0.97385621, 0.97385621,\n",
      "        0.97385621],\n",
      "       [0.96862745, 0.96862745, 0.96862745, ..., 0.96862745, 0.96862745,\n",
      "        0.96862745]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "print(GenerateNextBatch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT*IMAGE_WIDTH])\n",
    "Y = tf.placeholder(tf.float32, [None, MAX_CAPTCHA*CHAR_SET_LEN])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "def crack_captcha_cnn(w_alpha=0.01, b_alpha=0.1):\n",
    "    # 将占位符 转换为 按照图片给的新样式\n",
    "    x = tf.reshape(X, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
    "\n",
    "    #w_c1_alpha = np.sqrt(2.0/(IMAGE_HEIGHT*IMAGE_WIDTH)) #\n",
    "    #w_c2_alpha = np.sqrt(2.0/(3*3*32))\n",
    "    #w_c3_alpha = np.sqrt(2.0/(3*3*64))\n",
    "    #w_d1_alpha = np.sqrt(2.0/(8*32*64))\n",
    "    #out_alpha = np.sqrt(2.0/1024)\n",
    "\n",
    "    # 3 conv layer\n",
    "    w_c1 = tf.Variable(w_alpha*tf.random_normal([3, 3, 1, 32])) # 从正太分布输出随机值\n",
    "    b_c1 = tf.Variable(b_alpha*tf.random_normal([32]))\n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides=[1, 1, 1, 1], padding='SAME'), b_c1))\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "\n",
    "    w_c2 = tf.Variable(w_alpha*tf.random_normal([3, 3, 32, 64]))\n",
    "    b_c2 = tf.Variable(b_alpha*tf.random_normal([64]))\n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv1, w_c2, strides=[1, 1, 1, 1], padding='SAME'), b_c2))\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "\n",
    "    w_c3 = tf.Variable(w_alpha*tf.random_normal([3, 3, 64, 64]))\n",
    "    b_c3 = tf.Variable(b_alpha*tf.random_normal([64]))\n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv2, w_c3, strides=[1, 1, 1, 1], padding='SAME'), b_c3))\n",
    "    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "\n",
    "    # Fully connected layer\n",
    "    w_d = tf.Variable(w_alpha*tf.random_normal([8*20*64, 1024]))\n",
    "    b_d = tf.Variable(b_alpha*tf.random_normal([1024]))\n",
    "    dense = tf.reshape(conv3, [-1, w_d.get_shape().as_list()[0]])\n",
    "    dense = tf.nn.relu(tf.add(tf.matmul(dense, w_d), b_d))\n",
    "    dense = tf.nn.dropout(dense, keep_prob)\n",
    "\n",
    "    w_out = tf.Variable(w_alpha*tf.random_normal([1024, MAX_CAPTCHA*CHAR_SET_LEN]))\n",
    "    b_out = tf.Variable(b_alpha*tf.random_normal([MAX_CAPTCHA*CHAR_SET_LEN]))\n",
    "    out = tf.add(tf.matmul(dense, w_out), b_out)\n",
    "    #out = tf.nn.softmax(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crack_captcha_cnn():\n",
    "    output = crack_captcha_cnn()\n",
    "    #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, Y))\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output, labels=Y))\n",
    "    # 最后一层用来分类的softmax和sigmoid有什么不同？\n",
    "    # optimizer 为了加快训练 learning_rate应该开始大，然后慢慢衰\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "    predict = tf.reshape(output, [-1, MAX_CAPTCHA, CHAR_SET_LEN])\n",
    "    max_idx_p = tf.argmax(predict, 2)\n",
    "    max_idx_l = tf.argmax(tf.reshape(Y, [-1, MAX_CAPTCHA, CHAR_SET_LEN]), 2)\n",
    "    correct_pred = tf.equal(max_idx_p, max_idx_l)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        while True:\n",
    "            batch_x, batch_y = GenerateNextBatch(64)\n",
    "            _, loss_ = sess.run([optimizer, loss], feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.75})\n",
    "            print(step, loss_)\n",
    "\n",
    "            # 每100 step计算一次准确率\n",
    "            if step % 100 == 0:\n",
    "                batch_x_test, batch_y_test = GenerateNextBatch(100)\n",
    "                acc = sess.run(accuracy, feed_dict={X: batch_x_test, Y: batch_y_test, keep_prob: 1.})\n",
    "                print(step, acc)\n",
    "                # 如果准确率大于50%,保存模型,完成训练\n",
    "                if acc > 0.7:\n",
    "                    saver.save(sess, \"crack_capcha.model\", global_step=step)\n",
    "                    break\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6866401\n",
      "0 0.0175\n",
      "1 0.56271255\n",
      "2 0.32768753\n",
      "3 0.116980836\n",
      "4 0.09543078\n",
      "5 0.14326423\n",
      "6 0.18288644\n",
      "7 0.1987783\n",
      "8 0.19781256\n",
      "9 0.18298851\n",
      "10 0.16309252\n",
      "11 0.1403823\n",
      "12 0.11629746\n",
      "13 0.10215574\n",
      "14 0.09243608\n",
      "15 0.09511829\n",
      "16 0.10445235\n",
      "17 0.1105131\n",
      "18 0.10641163\n",
      "19 0.099039696\n",
      "20 0.09270748\n",
      "21 0.0866262\n",
      "22 0.08510802\n",
      "23 0.08434649\n",
      "24 0.08676955\n",
      "25 0.08881244\n",
      "26 0.09053704\n",
      "27 0.09085564\n",
      "28 0.08875621\n",
      "29 0.090805456\n",
      "30 0.08736399\n",
      "31 0.088841714\n",
      "32 0.08665676\n",
      "33 0.088257775\n",
      "34 0.0881567\n",
      "35 0.08678137\n",
      "36 0.087650485\n",
      "37 0.08635847\n",
      "38 0.0855105\n",
      "39 0.08499701\n",
      "40 0.08451037\n",
      "41 0.084284246\n",
      "42 0.08380719\n",
      "43 0.08519139\n",
      "44 0.08431613\n",
      "45 0.08421059\n",
      "46 0.08473195\n",
      "47 0.08479389\n",
      "48 0.08424851\n",
      "49 0.08456392\n",
      "50 0.08321936\n",
      "51 0.08409954\n",
      "52 0.08460499\n",
      "53 0.08490343\n",
      "54 0.08511301\n",
      "55 0.08511762\n",
      "56 0.083990805\n",
      "57 0.08469956\n",
      "58 0.084201075\n",
      "59 0.08348214\n",
      "60 0.08404818\n",
      "61 0.08423814\n",
      "62 0.08364153\n",
      "63 0.08464364\n",
      "64 0.08431364\n",
      "65 0.08424005\n",
      "66 0.08386927\n",
      "67 0.08443513\n",
      "68 0.08398487\n",
      "69 0.0840735\n",
      "70 0.08373485\n",
      "71 0.08400131\n",
      "72 0.08492121\n",
      "73 0.08479445\n",
      "74 0.0836038\n",
      "75 0.08397761\n",
      "76 0.08494897\n",
      "77 0.08419975\n",
      "78 0.08320258\n",
      "79 0.0837535\n",
      "80 0.08386355\n",
      "81 0.08350786\n",
      "82 0.08488455\n",
      "83 0.08491998\n",
      "84 0.08453674\n",
      "85 0.08309223\n",
      "86 0.083808705\n",
      "87 0.084713824\n",
      "88 0.0843052\n",
      "89 0.08388239\n",
      "90 0.08386396\n",
      "91 0.084202245\n",
      "92 0.08352372\n",
      "93 0.08413836\n",
      "94 0.084486276\n",
      "95 0.08415102\n",
      "96 0.0838395\n",
      "97 0.084375456\n",
      "98 0.08354049\n",
      "99 0.08460949\n",
      "100 0.08432862\n",
      "100 0.025\n",
      "101 0.08393178\n",
      "102 0.08427772\n",
      "103 0.08405658\n",
      "104 0.084876284\n",
      "105 0.085086145\n",
      "106 0.08404344\n",
      "107 0.08374427\n",
      "108 0.084298134\n",
      "109 0.08329435\n",
      "110 0.08423127\n",
      "111 0.08378907\n",
      "112 0.084278375\n",
      "113 0.08384633\n",
      "114 0.0839413\n",
      "115 0.08422318\n",
      "116 0.08386128\n",
      "117 0.0833665\n",
      "118 0.08394855\n",
      "119 0.083194226\n",
      "120 0.08326487\n",
      "121 0.08434528\n",
      "122 0.08387027\n",
      "123 0.084494434\n",
      "124 0.08339717\n",
      "125 0.08480639\n",
      "126 0.083660364\n",
      "127 0.08442574\n",
      "128 0.083609685\n",
      "129 0.08375624\n",
      "130 0.083156385\n",
      "131 0.08374731\n",
      "132 0.08352834\n",
      "133 0.08422385\n",
      "134 0.08499319\n",
      "135 0.08354109\n",
      "136 0.08397367\n",
      "137 0.08433958\n",
      "138 0.08434034\n",
      "139 0.08359292\n",
      "140 0.08464721\n",
      "141 0.08354089\n",
      "142 0.0842259\n",
      "143 0.08330641\n",
      "144 0.08380666\n",
      "145 0.084428616\n",
      "146 0.084104106\n",
      "147 0.08309641\n",
      "148 0.083948724\n",
      "149 0.08455648\n",
      "150 0.083849326\n",
      "151 0.0835573\n",
      "152 0.08389178\n",
      "153 0.0832201\n",
      "154 0.08348685\n",
      "155 0.083903536\n",
      "156 0.08418635\n",
      "157 0.084011644\n",
      "158 0.08410087\n",
      "159 0.08462618\n",
      "160 0.08351487\n",
      "161 0.0835812\n",
      "162 0.08394596\n",
      "163 0.08371301\n",
      "164 0.08336581\n",
      "165 0.08358233\n",
      "166 0.08400351\n",
      "167 0.08433834\n",
      "168 0.08423165\n",
      "169 0.083528355\n",
      "170 0.08401952\n",
      "171 0.0841092\n",
      "172 0.08364805\n",
      "173 0.08373456\n",
      "174 0.084435456\n",
      "175 0.08415503\n",
      "176 0.08335029\n",
      "177 0.083601415\n",
      "178 0.08427798\n",
      "179 0.08386098\n",
      "180 0.0839977\n",
      "181 0.08391852\n",
      "182 0.083914496\n",
      "183 0.08359951\n",
      "184 0.08361959\n",
      "185 0.08298753\n",
      "186 0.08358297\n",
      "187 0.08395134\n",
      "188 0.08415783\n",
      "189 0.08401602\n",
      "190 0.08472905\n",
      "191 0.083316326\n",
      "192 0.0839589\n",
      "193 0.08382082\n",
      "194 0.08414076\n",
      "195 0.08368374\n",
      "196 0.083648466\n",
      "197 0.08407651\n",
      "198 0.08407911\n",
      "199 0.08402471\n",
      "200 0.083587125\n",
      "200 0.015\n",
      "201 0.08370993\n",
      "202 0.08424104\n",
      "203 0.08339539\n",
      "204 0.08357469\n",
      "205 0.08381378\n",
      "206 0.08334774\n",
      "207 0.08403161\n",
      "208 0.08409307\n",
      "209 0.08379973\n",
      "210 0.08331579\n",
      "211 0.08377438\n",
      "212 0.0834612\n",
      "213 0.08408048\n",
      "214 0.08318923\n",
      "215 0.08401079\n",
      "216 0.08397499\n",
      "217 0.08427397\n",
      "218 0.08394419\n",
      "219 0.083997205\n",
      "220 0.084366545\n",
      "221 0.084511384\n",
      "222 0.08342698\n",
      "223 0.08445221\n",
      "224 0.08370744\n",
      "225 0.083284006\n",
      "226 0.08330116\n",
      "227 0.08353252\n",
      "228 0.083540134\n",
      "229 0.08345455\n",
      "230 0.08317023\n",
      "231 0.08368355\n",
      "232 0.08287598\n",
      "233 0.083718106\n",
      "234 0.08403346\n",
      "235 0.08454235\n",
      "236 0.083659545\n",
      "237 0.08389095\n",
      "238 0.08371687\n",
      "239 0.08420145\n",
      "240 0.084276445\n",
      "241 0.08343191\n",
      "242 0.08426723\n",
      "243 0.08346844\n",
      "244 0.083758794\n",
      "245 0.084319666\n",
      "246 0.083971195\n",
      "247 0.084619395\n",
      "248 0.083644696\n",
      "249 0.08372401\n",
      "250 0.08410111\n",
      "251 0.083966054\n",
      "252 0.08360312\n",
      "253 0.08474659\n",
      "254 0.08416994\n",
      "255 0.08375453\n",
      "256 0.083805054\n",
      "257 0.083751656\n",
      "258 0.08365942\n",
      "259 0.08365459\n",
      "260 0.08356564\n",
      "261 0.08364125\n",
      "262 0.08375522\n",
      "263 0.0845468\n",
      "264 0.08372052\n",
      "265 0.08401486\n",
      "266 0.08325443\n",
      "267 0.08343035\n",
      "268 0.083954066\n",
      "269 0.083210215\n",
      "270 0.083378226\n",
      "271 0.082914256\n",
      "272 0.08378493\n",
      "273 0.08451176\n",
      "274 0.083341494\n",
      "275 0.08409836\n",
      "276 0.0845212\n",
      "277 0.08378606\n",
      "278 0.08376045\n",
      "279 0.08426486\n",
      "280 0.08406388\n",
      "281 0.08399358\n",
      "282 0.08368906\n",
      "283 0.08368128\n",
      "284 0.08374597\n",
      "285 0.08363238\n",
      "286 0.08370303\n",
      "287 0.083509974\n",
      "288 0.083627515\n",
      "289 0.0835954\n",
      "290 0.08405581\n",
      "291 0.083882\n",
      "292 0.08449956\n",
      "293 0.08391114\n",
      "294 0.08429081\n",
      "295 0.08346865\n",
      "296 0.083856806\n",
      "297 0.08315863\n",
      "298 0.08360385\n",
      "299 0.08323328\n",
      "300 0.08313473\n",
      "300 0.015\n",
      "301 0.08367516\n",
      "302 0.08390216\n",
      "303 0.08377541\n",
      "304 0.08349906\n",
      "305 0.082996495\n",
      "306 0.08368023\n",
      "307 0.08399419\n",
      "308 0.08374214\n",
      "309 0.08367986\n",
      "310 0.083111085\n",
      "311 0.08417496\n",
      "312 0.08384548\n",
      "313 0.08398739\n",
      "314 0.08384109\n",
      "315 0.083905295\n",
      "316 0.08323983\n",
      "317 0.08364102\n",
      "318 0.08329478\n",
      "319 0.08371993\n",
      "320 0.083461255\n",
      "321 0.08443048\n",
      "322 0.08431086\n",
      "323 0.08377361\n",
      "324 0.08304504\n",
      "325 0.08297797\n",
      "326 0.08349989\n",
      "327 0.08395763\n",
      "328 0.08304421\n",
      "329 0.0835719\n",
      "330 0.08394589\n",
      "331 0.083399855\n",
      "332 0.08358984\n",
      "333 0.08391651\n",
      "334 0.08364088\n",
      "335 0.08376071\n",
      "336 0.0831226\n",
      "337 0.08392183\n",
      "338 0.083892606\n",
      "339 0.08341694\n",
      "340 0.083485916\n",
      "341 0.083875544\n",
      "342 0.08329743\n",
      "343 0.083862126\n",
      "344 0.083768554\n",
      "345 0.08345899\n",
      "346 0.08397322\n",
      "347 0.08344655\n",
      "348 0.08395449\n",
      "349 0.083708316\n",
      "350 0.083509855\n",
      "351 0.08434967\n",
      "352 0.08359665\n",
      "353 0.08369758\n",
      "354 0.08375078\n",
      "355 0.083317205\n",
      "356 0.0836912\n",
      "357 0.08413591\n",
      "358 0.08383027\n",
      "359 0.08360162\n",
      "360 0.0829583\n",
      "361 0.08346477\n",
      "362 0.0838463\n",
      "363 0.0839814\n",
      "364 0.083121985\n",
      "365 0.0832318\n",
      "366 0.08369212\n",
      "367 0.0832695\n",
      "368 0.083725296\n",
      "369 0.08382742\n",
      "370 0.08353713\n",
      "371 0.08413498\n",
      "372 0.083443694\n",
      "373 0.08344855\n",
      "374 0.082939915\n",
      "375 0.08378772\n",
      "376 0.08395257\n",
      "377 0.08401517\n",
      "378 0.08342219\n",
      "379 0.08371247\n",
      "380 0.083410725\n",
      "381 0.08349894\n",
      "382 0.083919294\n",
      "383 0.08342619\n",
      "384 0.08381901\n",
      "385 0.0833304\n",
      "386 0.08317907\n",
      "387 0.08414355\n",
      "388 0.08344389\n",
      "389 0.08370444\n",
      "390 0.08433651\n",
      "391 0.083512776\n",
      "392 0.083738945\n",
      "393 0.083675765\n",
      "394 0.08407574\n",
      "395 0.08374656\n",
      "396 0.0833036\n",
      "397 0.083984636\n",
      "398 0.0835419\n",
      "399 0.083344735\n",
      "400 0.08360953\n",
      "400 0.01\n",
      "401 0.08319457\n",
      "402 0.08375623\n",
      "403 0.08342941\n",
      "404 0.08366494\n",
      "405 0.08351166\n",
      "406 0.08334852\n",
      "407 0.08322391\n",
      "408 0.08323772\n",
      "409 0.0834007\n",
      "410 0.083599254\n",
      "411 0.08316461\n",
      "412 0.08389447\n",
      "413 0.08380828\n",
      "414 0.08377447\n",
      "415 0.08353417\n",
      "416 0.083004646\n",
      "417 0.08386043\n",
      "418 0.0838416\n",
      "419 0.08375445\n",
      "420 0.08334852\n",
      "421 0.08353061\n",
      "422 0.083662815\n",
      "423 0.08356988\n",
      "424 0.08310652\n",
      "425 0.08410994\n",
      "426 0.08337922\n",
      "427 0.083766356\n",
      "428 0.08385137\n",
      "429 0.083867185\n",
      "430 0.08355075\n",
      "431 0.08340671\n",
      "432 0.08301118\n",
      "433 0.08352441\n",
      "434 0.083988406\n",
      "435 0.08321646\n",
      "436 0.08318221\n",
      "437 0.083117135\n",
      "438 0.08414828\n",
      "439 0.083134174\n",
      "440 0.08344246\n",
      "441 0.08331384\n",
      "442 0.08389073\n",
      "443 0.083985895\n",
      "444 0.083710104\n",
      "445 0.08353407\n",
      "446 0.08403437\n",
      "447 0.0831984\n",
      "448 0.08341821\n",
      "449 0.0832786\n",
      "450 0.083400145\n",
      "451 0.083364666\n",
      "452 0.083409585\n",
      "453 0.083036296\n",
      "454 0.08351209\n",
      "455 0.08314937\n",
      "456 0.08332602\n",
      "457 0.083946735\n",
      "458 0.08384643\n",
      "459 0.08337513\n",
      "460 0.08342742\n",
      "461 0.08312535\n",
      "462 0.08404498\n",
      "463 0.08321793\n",
      "464 0.08349043\n",
      "465 0.083496496\n",
      "466 0.084068514\n",
      "467 0.08322339\n",
      "468 0.0833982\n",
      "469 0.08379116\n",
      "470 0.08330772\n",
      "471 0.083854735\n",
      "472 0.083588965\n",
      "473 0.08342293\n",
      "474 0.083642714\n",
      "475 0.08342631\n",
      "476 0.08319452\n",
      "477 0.08346813\n",
      "478 0.08364502\n",
      "479 0.08354913\n",
      "480 0.08381104\n",
      "481 0.08324591\n",
      "482 0.08380897\n",
      "483 0.08388907\n",
      "484 0.08358428\n",
      "485 0.0841172\n",
      "486 0.08365773\n",
      "487 0.083460756\n",
      "488 0.08352812\n",
      "489 0.083446205\n",
      "490 0.08394338\n",
      "491 0.08321414\n",
      "492 0.08326912\n",
      "493 0.083622165\n",
      "494 0.083317295\n",
      "495 0.08390463\n",
      "496 0.083304726\n",
      "497 0.08304596\n",
      "498 0.083256304\n",
      "499 0.08328056\n",
      "500 0.083312005\n",
      "500 0.025\n",
      "501 0.08389074\n",
      "502 0.08360721\n",
      "503 0.08313821\n",
      "504 0.08342966\n",
      "505 0.08342463\n",
      "506 0.083524175\n",
      "507 0.08321897\n",
      "508 0.083716124\n",
      "509 0.08355059\n",
      "510 0.08287905\n",
      "511 0.08330696\n",
      "512 0.08358636\n",
      "513 0.08384542\n",
      "514 0.08268046\n",
      "515 0.083699085\n",
      "516 0.08385132\n",
      "517 0.083637446\n",
      "518 0.08381467\n",
      "519 0.08341172\n",
      "520 0.083079904\n",
      "521 0.08387059\n",
      "522 0.08303813\n",
      "523 0.08344501\n",
      "524 0.08345162\n",
      "525 0.08328075\n",
      "526 0.08340085\n",
      "527 0.08332962\n",
      "528 0.08414474\n",
      "529 0.08334551\n",
      "530 0.083674945\n",
      "531 0.083484665\n",
      "532 0.08345819\n",
      "533 0.08344633\n",
      "534 0.08344685\n",
      "535 0.083627686\n",
      "536 0.083099835\n",
      "537 0.08387024\n",
      "538 0.083551005\n",
      "539 0.08385835\n",
      "540 0.08365318\n",
      "541 0.08388808\n",
      "542 0.08352229\n",
      "543 0.0834879\n",
      "544 0.08317163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545 0.08301769\n",
      "546 0.08356937\n",
      "547 0.08359177\n",
      "548 0.084048994\n",
      "549 0.08322386\n",
      "550 0.08379256\n",
      "551 0.08310815\n",
      "552 0.083456166\n",
      "553 0.08363953\n",
      "554 0.08326316\n",
      "555 0.08369629\n",
      "556 0.0834887\n",
      "557 0.08358735\n",
      "558 0.083674915\n",
      "559 0.083206184\n",
      "560 0.08357269\n",
      "561 0.083478644\n",
      "562 0.08367217\n",
      "563 0.083015166\n",
      "564 0.08345178\n",
      "565 0.08342552\n",
      "566 0.08300889\n",
      "567 0.083032474\n",
      "568 0.08376707\n",
      "569 0.08364705\n",
      "570 0.08326602\n",
      "571 0.08353613\n",
      "572 0.0833978\n",
      "573 0.08355791\n",
      "574 0.08340158\n",
      "575 0.083852135\n",
      "576 0.08339947\n",
      "577 0.08306447\n",
      "578 0.083484635\n",
      "579 0.08364915\n",
      "580 0.08327292\n",
      "581 0.08282259\n",
      "582 0.08324402\n",
      "583 0.08339391\n",
      "584 0.08360209\n",
      "585 0.08298487\n",
      "586 0.08327268\n",
      "587 0.08346831\n",
      "588 0.08344033\n",
      "589 0.08305988\n",
      "590 0.08320447\n",
      "591 0.08393342\n",
      "592 0.08326478\n",
      "593 0.08332265\n",
      "594 0.0833304\n",
      "595 0.08316163\n",
      "596 0.08376026\n",
      "597 0.08338142\n",
      "598 0.083440766\n",
      "599 0.08353056\n",
      "600 0.083605446\n",
      "600 0.02\n",
      "601 0.08346036\n",
      "602 0.083478406\n",
      "603 0.08304024\n",
      "604 0.08357434\n",
      "605 0.08365244\n",
      "606 0.08321482\n",
      "607 0.08339507\n",
      "608 0.08320891\n",
      "609 0.08356193\n",
      "610 0.08337904\n",
      "611 0.08343169\n",
      "612 0.08323626\n",
      "613 0.08380346\n",
      "614 0.08345904\n",
      "615 0.083680615\n",
      "616 0.08299634\n",
      "617 0.08297237\n",
      "618 0.08268753\n",
      "619 0.08317709\n",
      "620 0.08360853\n",
      "621 0.08362286\n",
      "622 0.083720535\n",
      "623 0.08320951\n",
      "624 0.08357783\n",
      "625 0.08317574\n",
      "626 0.08379036\n",
      "627 0.083399035\n",
      "628 0.08323136\n",
      "629 0.08329286\n",
      "630 0.08389791\n",
      "631 0.08356997\n",
      "632 0.08327529\n",
      "633 0.08303908\n",
      "634 0.083527625\n",
      "635 0.083309785\n",
      "636 0.08317882\n",
      "637 0.08354321\n",
      "638 0.083658256\n",
      "639 0.082867004\n",
      "640 0.083501875\n",
      "641 0.083201535\n",
      "642 0.08371297\n",
      "643 0.08351605\n",
      "644 0.08308568\n",
      "645 0.083033845\n",
      "646 0.08286722\n",
      "647 0.08346676\n",
      "648 0.083634764\n",
      "649 0.083446234\n",
      "650 0.083463915\n",
      "651 0.08327453\n",
      "652 0.08356171\n",
      "653 0.083558515\n",
      "654 0.08362594\n",
      "655 0.08321519\n",
      "656 0.08380611\n",
      "657 0.08346108\n",
      "658 0.08372353\n",
      "659 0.08327921\n",
      "660 0.08319446\n",
      "661 0.083161525\n",
      "662 0.083662465\n",
      "663 0.08311263\n",
      "664 0.08321604\n",
      "665 0.083994046\n",
      "666 0.08339376\n",
      "667 0.08325568\n",
      "668 0.08291087\n",
      "669 0.083139576\n",
      "670 0.08346947\n",
      "671 0.08388752\n",
      "672 0.083957456\n",
      "673 0.08327415\n",
      "674 0.08353172\n",
      "675 0.08416302\n",
      "676 0.08407906\n",
      "677 0.08371431\n",
      "678 0.08348339\n",
      "679 0.08346351\n",
      "680 0.08327264\n",
      "681 0.0829529\n",
      "682 0.08327232\n",
      "683 0.08329767\n",
      "684 0.08390949\n",
      "685 0.083169885\n",
      "686 0.083074756\n",
      "687 0.0833302\n",
      "688 0.08331717\n",
      "689 0.08306456\n",
      "690 0.083839804\n",
      "691 0.083388604\n",
      "692 0.083387144\n",
      "693 0.0832672\n",
      "694 0.083452165\n",
      "695 0.08341292\n",
      "696 0.08344716\n",
      "697 0.08351677\n",
      "698 0.0834739\n",
      "699 0.08337587\n",
      "700 0.083433025\n",
      "700 0.0175\n",
      "701 0.08332726\n",
      "702 0.08380701\n",
      "703 0.083003566\n",
      "704 0.08303742\n",
      "705 0.08336973\n",
      "706 0.08325046\n",
      "707 0.08284833\n",
      "708 0.082958505\n",
      "709 0.083406754\n",
      "710 0.083325095\n",
      "711 0.08344633\n",
      "712 0.08309893\n",
      "713 0.082972504\n",
      "714 0.08286189\n",
      "715 0.083236985\n",
      "716 0.08337836\n",
      "717 0.08329376\n",
      "718 0.08411287\n",
      "719 0.08270725\n",
      "720 0.083134\n",
      "721 0.08349125\n",
      "722 0.08375843\n",
      "723 0.08344778\n",
      "724 0.083379\n",
      "725 0.08344306\n",
      "726 0.08361919\n",
      "727 0.08332156\n",
      "728 0.083989695\n",
      "729 0.08337037\n",
      "730 0.08359512\n",
      "731 0.08314016\n",
      "732 0.083434574\n",
      "733 0.08363175\n",
      "734 0.08311241\n",
      "735 0.083600074\n",
      "736 0.083524786\n",
      "737 0.08341935\n",
      "738 0.083055556\n",
      "739 0.0836634\n",
      "740 0.08358113\n",
      "741 0.083286785\n",
      "742 0.08299746\n",
      "743 0.083844095\n",
      "744 0.08335757\n",
      "745 0.08328626\n",
      "746 0.08317624\n",
      "747 0.08335339\n",
      "748 0.083580814\n",
      "749 0.0836389\n",
      "750 0.08337835\n",
      "751 0.08353581\n",
      "752 0.08289861\n",
      "753 0.08380994\n",
      "754 0.08327018\n",
      "755 0.08353667\n",
      "756 0.08296978\n",
      "757 0.083325766\n",
      "758 0.08354228\n",
      "759 0.082820125\n",
      "760 0.0838001\n",
      "761 0.08376071\n",
      "762 0.08295001\n",
      "763 0.08292944\n",
      "764 0.08363317\n",
      "765 0.08317365\n",
      "766 0.08326603\n",
      "767 0.083372526\n",
      "768 0.08335843\n",
      "769 0.083226465\n",
      "770 0.08292443\n",
      "771 0.08352664\n",
      "772 0.08356781\n",
      "773 0.083539516\n",
      "774 0.08324557\n",
      "775 0.083394684\n",
      "776 0.08307997\n",
      "777 0.08311888\n",
      "778 0.08362715\n",
      "779 0.08431341\n",
      "780 0.083505705\n",
      "781 0.08350834\n",
      "782 0.08341081\n",
      "783 0.083874166\n",
      "784 0.083728\n",
      "785 0.08359565\n",
      "786 0.08332868\n",
      "787 0.0832121\n",
      "788 0.08373694\n",
      "789 0.083567806\n",
      "790 0.083440445\n",
      "791 0.08331734\n",
      "792 0.08308426\n",
      "793 0.083460286\n",
      "794 0.083304144\n",
      "795 0.083292656\n",
      "796 0.083644\n",
      "797 0.08319392\n",
      "798 0.08323205\n",
      "799 0.08357061\n",
      "800 0.08358132\n",
      "800 0.02\n",
      "801 0.0834901\n",
      "802 0.08363338\n",
      "803 0.08360381\n",
      "804 0.08340499\n",
      "805 0.08367453\n",
      "806 0.083180964\n",
      "807 0.0835445\n",
      "808 0.08348965\n",
      "809 0.083073646\n",
      "810 0.08304129\n",
      "811 0.0839499\n",
      "812 0.08389031\n",
      "813 0.083375715\n",
      "814 0.08314135\n",
      "815 0.0837846\n",
      "816 0.08322613\n",
      "817 0.08357337\n",
      "818 0.08363793\n",
      "819 0.08347139\n",
      "820 0.08314857\n",
      "821 0.08341114\n",
      "822 0.08309857\n",
      "823 0.084130995\n",
      "824 0.082832195\n",
      "825 0.0830521\n",
      "826 0.083313696\n",
      "827 0.08335638\n",
      "828 0.08302124\n",
      "829 0.08298839\n",
      "830 0.08355064\n",
      "831 0.08344441\n",
      "832 0.08363886\n",
      "833 0.083170496\n",
      "834 0.083527364\n",
      "835 0.0832422\n",
      "836 0.08332172\n",
      "837 0.08361857\n",
      "838 0.083474666\n",
      "839 0.08338985\n",
      "840 0.08320115\n",
      "841 0.08325817\n",
      "842 0.08328984\n",
      "843 0.08328119\n",
      "844 0.08325964\n",
      "845 0.08332099\n",
      "846 0.0834538\n",
      "847 0.08343715\n",
      "848 0.08285508\n",
      "849 0.08349904\n",
      "850 0.08292704\n",
      "851 0.08366154\n",
      "852 0.083189234\n",
      "853 0.08301578\n",
      "854 0.08401497\n",
      "855 0.08335446\n",
      "856 0.08331364\n",
      "857 0.08377038\n",
      "858 0.083704606\n",
      "859 0.083127394\n",
      "860 0.08312599\n",
      "861 0.082852475\n",
      "862 0.08292227\n",
      "863 0.08329339\n",
      "864 0.08310701\n",
      "865 0.08335398\n",
      "866 0.08370693\n",
      "867 0.083294764\n",
      "868 0.08310847\n",
      "869 0.08322265\n",
      "870 0.08367239\n",
      "871 0.08258166\n",
      "872 0.08324966\n",
      "873 0.0831356\n",
      "874 0.08381484\n",
      "875 0.08316734\n",
      "876 0.0833945\n",
      "877 0.083646506\n",
      "878 0.083905496\n",
      "879 0.08299784\n",
      "880 0.08307247\n",
      "881 0.08407238\n",
      "882 0.08335925\n",
      "883 0.08346292\n",
      "884 0.08313136\n",
      "885 0.08325237\n",
      "886 0.083291866\n",
      "887 0.08386044\n",
      "888 0.0828868\n",
      "889 0.08304389\n",
      "890 0.08352471\n",
      "891 0.083539575\n",
      "892 0.08335155\n",
      "893 0.08302901\n",
      "894 0.08340324\n",
      "895 0.08390227\n",
      "896 0.083213575\n",
      "897 0.083498545\n",
      "898 0.08327716\n",
      "899 0.08343097\n",
      "900 0.08381264\n",
      "900 0.015\n",
      "901 0.08351406\n",
      "902 0.08381413\n",
      "903 0.08272565\n",
      "904 0.083187036\n",
      "905 0.083441466\n",
      "906 0.08305707\n",
      "907 0.0833096\n",
      "908 0.08315323\n",
      "909 0.08327942\n",
      "910 0.08349355\n",
      "911 0.08349154\n",
      "912 0.08361358\n",
      "913 0.0837165\n",
      "914 0.08308266\n",
      "915 0.0831239\n",
      "916 0.08347147\n",
      "917 0.08306733\n",
      "918 0.08329885\n",
      "919 0.08338582\n",
      "920 0.08338353\n",
      "921 0.08361511\n",
      "922 0.0829134\n",
      "923 0.08335362\n",
      "924 0.08320298\n",
      "925 0.08323083\n",
      "926 0.08318283\n",
      "927 0.083232366\n",
      "928 0.08382287\n",
      "929 0.08341911\n",
      "930 0.08339737\n",
      "931 0.08369073\n",
      "932 0.08281345\n",
      "933 0.08359764\n",
      "934 0.08348337\n",
      "935 0.08325883\n",
      "936 0.08312087\n",
      "937 0.08355635\n",
      "938 0.08315202\n",
      "939 0.08311823\n",
      "940 0.08369752\n",
      "941 0.08307739\n",
      "942 0.08309163\n",
      "943 0.08331124\n",
      "944 0.0828517\n",
      "945 0.08361506\n",
      "946 0.08387918\n",
      "947 0.0832213\n",
      "948 0.08307206\n",
      "949 0.083282575\n",
      "950 0.083265245\n",
      "951 0.083526984\n"
     ]
    }
   ],
   "source": [
    "train_crack_captcha_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
